{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, pickle, multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "from collections import Counter\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"resources/captions with embeddings/*shirt*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"nontracked/dataset/shirt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_name):\n",
    "    return image.load_img(dataset_path+image_name+\".jpg\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(a, b):\n",
    "    return 1 - spatial.distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image):\n",
    "    return data[data[0]==image][1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(img):\n",
    "    fd, hog_image = hog(image.img_to_array(load_image(img)), orientations=8, pixels_per_cell=(3, 3),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    \n",
    "    return hog_image.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/captions with embeddings/cap.shirt.train.json') as f:\n",
    "    train = json.load(f)\n",
    "with open('resources/captions with embeddings/cap.shirt.test.json') as f:\n",
    "    test = json.load(f)\n",
    "with open('resources/captions with embeddings/cap.shirt.val.json') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"nontracked/dataset/shirt/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [i.split(\"/\")[-1][:-4] for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = multiprocessing.Pool(45)\n",
    "# image_embeddings = p.map(get_hog, images)\n",
    "# image_embeddings = np.array(image_embeddings)\n",
    "# pickle.dump(image_embeddings, open(\"nontracked/image_embeddings_shirt\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = pickle.load(open(\"nontracked/image_embeddings_shirt\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([images, image_embeddings]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_image_embedding(image):\n",
    "    return data[data[0]==image][1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_splits/split.shirt.train.json') as f:\n",
    "    train_split = json.load(f)\n",
    "train_split = list(set(train_split).intersection(set(data[0].values)))\n",
    "\n",
    "with open('image_splits/split.shirt.val.json') as f:\n",
    "    val_split = json.load(f)\n",
    "val_split = list(set(val_split).intersection(set(data[0].values)))\n",
    "\n",
    "with open('image_splits/split.shirt.test.json') as f:\n",
    "    test_split = json.load(f)\n",
    "test_split = list(set(test_split).intersection(set(data[0].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_split), len(val_split), len(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text = {i:[] for i in train_split}\n",
    "# for i in tqdm(train):\n",
    "    \n",
    "#     if i['target'] in train_split:\n",
    "#         train_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "#     if i['candidate'] in train_split:\n",
    "#         train_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter([len(train_text[i]) for i in train_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_text = {i:[] for i in val_split}\n",
    "# for i in tqdm(val):\n",
    "    \n",
    "#     if i['target'] in val_split:\n",
    "#         val_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "#     if i['candidate'] in val_split:\n",
    "#         val_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = {i:[] for i in test_split}\n",
    "for i in tqdm(test):\n",
    "    \n",
    "#     if i['target'] in test_split:\n",
    "#         test_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "    if i['candidate'] in test_split:\n",
    "        test_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"nontracked/enwiki_dbow/doc2vec.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = g.Doc2Vec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_embeds = {}\n",
    "\n",
    "# for i in tqdm(train_text):\n",
    "#     t = train_text[i]\n",
    "#     if len(t) > 0:\n",
    "#         text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_text_embeds = {}\n",
    "\n",
    "# for i in tqdm(val_text):\n",
    "#     t = val_text[i]\n",
    "#     if len(t) > 0:\n",
    "#         val_text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_embeds = {}\n",
    "\n",
    "for i in tqdm(test_text):\n",
    "    t = test_text[i]\n",
    "    if len(t) > 0:\n",
    "        test_text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(v):\n",
    "    candidate = v['candidate']\n",
    "#     target_caption = v['caption_embeds'][0]\n",
    "\n",
    "    target_caption = doc2vec.infer_vector(\" \".join(v['captions']).split(\" \")).tolist()\n",
    "    \n",
    "    k = []\n",
    "\n",
    "    rankings = []\n",
    "    for t in test_split:\n",
    "        s = 0\n",
    "        s += get_cosine(get_hog_image_embedding(candidate), get_hog_image_embedding(t))\n",
    "\n",
    "        if t in test_text_embeds:\n",
    "            p = get_cosine(target_caption, test_text_embeds[t])\n",
    "            rankings.append(s*0.2 + p*0.8)\n",
    "            k.append(2)\n",
    "        else:\n",
    "            rankings.append(s/2)\n",
    "            k.append(1)\n",
    "\n",
    "    a = np.array(rankings)\n",
    "    a = np.nan_to_num(a, 0)\n",
    "    http://192.168.29.83:8044/user/william18026/notebooks/fashion-iq/traditional_shirt.ipynb#\n",
    "    pro = np.take(test_split, a.argsort()[::-1])\n",
    "    d = np.where(pro==candidate)\n",
    "    pro = np.delete(pro, d)[:50].tolist()\n",
    "    \n",
    "    return {\"candidate\": v['candidate'], \"ranking\": pro} #, \"k\": np.take(k, a.argsort()[::-1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_result(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Pool(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = p.map(get_result, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shirt.predict.json', 'w') as outfile:\n",
    "    json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(r['ranking']=='B0077SM1Z0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings = np.load(\"nontracked/image_embeddings/dress.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('nontracked/image_embeddings/image_embeddings_order.pickle', 'rb') as f:\n",
    "#     image_order = pickle.load(f)['dress']\n",
    "# image_order = [i.split(\"/\")[-1][:-4] for i in image_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame([image_order, image_embeddings]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text_has_caption = [i for i in train_text if len(train_text[i])>0]\n",
    "# train_text_no_caption = [i for i in train_text if len(train_text[i])==0]\n",
    "# len(train_text_no_caption), len(train_text_has_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings_has_caption = []\n",
    "# for i in tqdm(train_text_has_caption):\n",
    "#     image_embeddings_has_caption.append(get_embeddings(i))\n",
    "# image_embeddings_has_caption = np.array(image_embeddings_has_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings_no_caption = []\n",
    "# for i in tqdm(train_text_no_caption):\n",
    "#     image_embeddings_no_caption.append(get_embeddings(i))\n",
    "# image_embeddings_no_caption = np.array(image_embeddings_no_caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_new",
   "language": "python",
   "name": "python3_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
