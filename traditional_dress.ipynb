{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, pickle, multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "from collections import Counter\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resources/captions with embeddings/cap.dress.train.json',\n",
       " 'resources/captions with embeddings/cap.dress.test.json',\n",
       " 'resources/captions with embeddings/cap.dress.val.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"resources/captions with embeddings/*dress*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"nontracked/dataset/dress/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_name):\n",
    "    return image.load_img(dataset_path+image_name+\".jpg\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(a, b):\n",
    "    return 1 - spatial.distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image):\n",
    "    return data[data[0]==image][1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(img):\n",
    "    fd, hog_image = hog(image.img_to_array(load_image(img)), orientations=8, pixels_per_cell=(3, 3),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    \n",
    "    return hog_image.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/captions with embeddings/cap.dress.train.json') as f:\n",
    "    train = json.load(f)\n",
    "with open('resources/captions with embeddings/cap.dress.test.json') as f:\n",
    "    test = json.load(f)\n",
    "with open('resources/captions with embeddings/cap.dress.val.json') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"nontracked/dataset/dress/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [i.split(\"/\")[-1][:-4] for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = multiprocessing.Pool(45)\n",
    "# image_embeddings = p.map(get_hog, images)\n",
    "# image_embeddings = np.array(image_embeddings)\n",
    "# pickle.dump(image_embeddings, open(\"nontracked/image_embeddings_dress\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = pickle.load(open(\"nontracked/image_embeddings_dress\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([images, image_embeddings]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B00CG60I4E</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B00DEX1OL4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B005Z957UY</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B0076R7UGM</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B0028AD76Y</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1\n",
       "0  B00CG60I4E  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1  B00DEX1OL4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2  B005Z957UY  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3  B0076R7UGM  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4  B0028AD76Y  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19074, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_image_embedding(image):\n",
    "    return data[data[0]==image][1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_splits/split.dress.train.json') as f:\n",
    "    train_split = json.load(f)\n",
    "train_split = list(set(train_split).intersection(set(data[0].values)))\n",
    "\n",
    "with open('image_splits/split.dress.val.json') as f:\n",
    "    val_split = json.load(f)\n",
    "val_split = list(set(val_split).intersection(set(data[0].values)))\n",
    "\n",
    "with open('image_splits/split.dress.test.json') as f:\n",
    "    test_split = json.load(f)\n",
    "test_split = list(set(test_split).intersection(set(data[0].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11444, 3817, 3813)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_split), len(val_split), len(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text = {i:[] for i in train_split}\n",
    "# for i in tqdm(train):\n",
    "    \n",
    "#     if i['target'] in train_split:\n",
    "#         train_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "#     if i['candidate'] in train_split:\n",
    "#         train_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter([len(train_text[i]) for i in train_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_text = {i:[] for i in val_split}\n",
    "# for i in tqdm(val):\n",
    "    \n",
    "#     if i['target'] in val_split:\n",
    "#         val_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "#     if i['candidate'] in val_split:\n",
    "#         val_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2024/2024 [00:00<00:00, 21113.86it/s]\n"
     ]
    }
   ],
   "source": [
    "test_text = {i:[] for i in test_split}\n",
    "for i in tqdm(test):\n",
    "    \n",
    "#     if i['target'] in test_split:\n",
    "#         test_text[i['target']].append(i['captions'][1])\n",
    "\n",
    "    if i['candidate'] in test_split:\n",
    "        test_text[i['candidate']].append(i['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"nontracked/enwiki_dbow/doc2vec.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = g.Doc2Vec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_embeds = {}\n",
    "\n",
    "# for i in tqdm(train_text):\n",
    "#     t = train_text[i]\n",
    "#     if len(t) > 0:\n",
    "#         text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_text_embeds = {}\n",
    "\n",
    "# for i in tqdm(val_text):\n",
    "#     t = val_text[i]\n",
    "#     if len(t) > 0:\n",
    "#         val_text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3813/3813 [00:01<00:00, 2380.74it/s]\n"
     ]
    }
   ],
   "source": [
    "test_text_embeds = {}\n",
    "\n",
    "for i in tqdm(test_text):\n",
    "    t = test_text[i]\n",
    "    if len(t) > 0:\n",
    "        test_text_embeds[i] = doc2vec.infer_vector(\" \".join(t).split(\" \")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(v):\n",
    "    candidate = v['candidate']\n",
    "#     target_caption = v['caption_embeds'][0]\n",
    "\n",
    "    target_caption = doc2vec.infer_vector(\" \".join(v['captions']).split(\" \")).tolist()\n",
    "    \n",
    "    k = []\n",
    "\n",
    "    rankings = []\n",
    "    for t in test_split:\n",
    "        s = 0\n",
    "        s += get_cosine(get_hog_image_embedding(candidate), get_hog_image_embedding(t))\n",
    "\n",
    "        if t in test_text_embeds:\n",
    "            p = get_cosine(target_caption, test_text_embeds[t])\n",
    "            rankings.append(s*0.2 + p*0.8)\n",
    "            k.append(2)\n",
    "        else:\n",
    "            rankings.append(s/2)\n",
    "            k.append(1)\n",
    "\n",
    "    a = np.array(rankings)\n",
    "    a = np.nan_to_num(a, 0)\n",
    "    \n",
    "    pro = np.take(test_split, a.argsort()[::-1])\n",
    "    d = np.where(pro==candidate)\n",
    "    pro = np.delete(pro, d)[:50].tolist()\n",
    "    \n",
    "    return {\"candidate\": v['candidate'], \"ranking\": pro} #, \"k\": np.take(k, a.argsort()[::-1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_result(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Pool(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = p.map(get_result, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dress.predict.json', 'w') as outfile:\n",
    "    json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(r['ranking']=='B0077SM1Z0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings = np.load(\"nontracked/image_embeddings/dress.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('nontracked/image_embeddings/image_embeddings_order.pickle', 'rb') as f:\n",
    "#     image_order = pickle.load(f)['dress']\n",
    "# image_order = [i.split(\"/\")[-1][:-4] for i in image_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame([image_order, image_embeddings]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text_has_caption = [i for i in train_text if len(train_text[i])>0]\n",
    "# train_text_no_caption = [i for i in train_text if len(train_text[i])==0]\n",
    "# len(train_text_no_caption), len(train_text_has_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings_has_caption = []\n",
    "# for i in tqdm(train_text_has_caption):\n",
    "#     image_embeddings_has_caption.append(get_embeddings(i))\n",
    "# image_embeddings_has_caption = np.array(image_embeddings_has_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_embeddings_no_caption = []\n",
    "# for i in tqdm(train_text_no_caption):\n",
    "#     image_embeddings_no_caption.append(get_embeddings(i))\n",
    "# image_embeddings_no_caption = np.array(image_embeddings_no_caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_new",
   "language": "python",
   "name": "python3_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
